{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Alibaba Category Crawler\n",
    " This Crawler will Scrape All the Product data Available in the 3rd Gen endpoint.\n",
    "\n",
    "> ### Importing Dependencies from Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# !pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main List for the product\n",
    "products_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening Browser and MAximize Window\n",
    "driver = webdriver.Firefox()\n",
    "driver.maximize_window()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Page Loader As for JS Randered respone with `pageLoader()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pageLoader():\n",
    "    # Scrolling down to the whole plage\n",
    "    scroll_Pause_time = 1\n",
    "    # Get page scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        # Scroll down to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        # wait to load the page\n",
    "        driver.implicitly_wait(3)\n",
    "        # compare new scroll height to last scroll height to break the loop\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    loading_report = 'Page Loading Done, starting to scrape data'\n",
    "    print(loading_report)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Data Selector Panel\n",
    "\n",
    "- `product_title = element_container[0].find_element(By.CSS_SELECTOR, 'p.elements-title-normal__content').text.strip()`\n",
    "- `product_price = element_container[0].find_element(By.CSS_SELECTOR, 'span.elements-offer-price-normal__price').text.strip()`\n",
    "- `moq_range = element_container[0].find_element(By.CSS_SELECTOR, 'span.element-offer-minorder-normal__value').text.strip()`\n",
    "- `seller_id_age = element_container[0].find_element(By.CSS_SELECTOR, 'span.seller-tag__year.flex-no-shrink').text.strip()`\n",
    "- `contact_supplier = element_container[0].find_element(By.CSS_SELECTOR, 'a.contact-supplier-btn').get_attribute('href')`\n",
    "- `product_img_link = element_container[30].find_element(By.CSS_SELECTOR, 'a.elements-title-normal').get_attribute('src')`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Getting Product Data with `getData()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  Getting the data from a single page\n",
    "def getData():\n",
    "    # wait for few more secs\n",
    "    driver.implicitly_wait(4)\n",
    "    # products container\n",
    "    element_container = driver.find_elements(By.CSS_SELECTOR, 'div.list-no-v2-inner')\n",
    "    for item in element_container:\n",
    "        product_dict = {\n",
    "        'product title' : item.find_element(By.CSS_SELECTOR, 'p.elements-title-normal__content').text.strip(),\n",
    "        'product price': item.find_element(By.CSS_SELECTOR, 'span.elements-offer-price-normal__price').text.strip(),\n",
    "        'MOQ' : item.find_element(By.CSS_SELECTOR, 'span.element-offer-minorder-normal__value').text.strip(),\n",
    "        'Seller ID age': item.find_element(By.CSS_SELECTOR, 'span.seller-tag__year.flex-no-shrink').text.strip(),\n",
    "        'contact supplier' : item.find_element(By.CSS_SELECTOR, 'a.contact-supplier-btn').get_attribute('href'),\n",
    "        'Product Img Link': item.find_element(By.CSS_SELECTOR, 'a.elements-title-normal').get_attribute('href')\n",
    "        }\n",
    "        products_list.append(product_dict)\n",
    "    page_scrap_report = f'all the data appened till :- \\n{products_list[-1]}'\n",
    "    print(page_scrap_report)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Saving Data to `products` folder using `saveTocsv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data to a CSV File\n",
    "def saveTocsv():\n",
    "    file_name = f\"./products/{input('Enter your csv_file_name: ')}.csv\"\n",
    "    field_names = products_list[0].keys()\n",
    "\n",
    "    with open(file_name, mode='a', encoding='utf-8', newline='') as file:\n",
    "        writet = csv.DictWriter(file, field_names)\n",
    "        writet.writeheader()\n",
    "        writet.writerows(products_list)\n",
    "        report = print(f'Data saved to {file_name}')\n",
    "    return report\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Pagination for a Certain range such as `4 Pages`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_url =input(\"Enter you category URL: \")\n",
    "for x in range(1, 11):\n",
    "    url = f'{category_url}{x}'\n",
    "    driver.get(url)\n",
    "    pageLoader()\n",
    "    getData()\n",
    "    driver.implicitly_wait(10)\n",
    "    print(f'Done scraping page no: {x}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### View Scraped products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(products_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_list[-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Data Extractors in Any Formates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveTocsv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
